{
 "metadata": {
  "name": "",
  "signature": "sha256:c1e8075edf9070eef655a0dfa6d5b79db1e454f12888b976933c06f0a6b01aad"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "On divise le data set entre train et test"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "On charge les libraries voulues :"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pyensae\n",
      "import pyquickhelper\n",
      "import pandas, sqlite3, os\n",
      "path = \"data/\"\n",
      "pathTrain = path+\"training_set/\"\n",
      "pathWD = \"\\\\\\\\paradis\\\\eleves\\\\BDonnot\\\\Bureau\\\\DonneesMassives\\\\\"\n",
      "os.chdir(pathWD)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "On se connecte au serveur"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pyquickhelper, pyensae\n",
      "params={\"blob_storage\":\"hdblobstorage\", \"password1\":\"\", \"hadoop_server\":\"clusterensaeazure1\", \"password2\":\"\", \"username\":\"alias\"}\n",
      "with open(\"password\",\"r\") as fPassWord :\n",
      "    for line in fPassWord :\n",
      "        li = line.split(\":\")\n",
      "        if li[0] == params[\"blob_storage\"] :\n",
      "            params[\"password1\"] = li[1].replace('\\n','').replace('\\r','')\n",
      "        elif li[0] == params[\"hadoop_server\"] :\n",
      "            params[\"password2\"] = li[1].replace('\\n','').replace('\\r','')\n",
      "blobstorage = params[\"blob_storage\"]\n",
      "blobpassword = params[\"password1\"]\n",
      "hadoop_server = params[\"hadoop_server\"]\n",
      "hadoop_password = params[\"password2\"]\n",
      "username = params[\"username\"]\n",
      "client, bs =  %hd_open\n",
      "client, bs,client.account_name,username\n",
      "#pyquickhelper.open_html_form(params=params,title=\"server + hadoop + credentials\", key_save=\"blobhp\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 22,
       "text": [
        "(<pyensae.remote.azure_connection.AzureClient at 0x3cfe0b8>,\n",
        " <azure.storage.blobservice.BlobService at 0x8e4c1d0>,\n",
        " 'hdblobstorage',\n",
        " 'alias')"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "On v\u00e9rifie que les pr\u00e9c\u00e9dents fichiers sont bien l\u00e0"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "l = %blob_containers\n",
      "l\n",
      "%blob_ls /any/DonnotLaugel"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>name</th>\n",
        "      <th>last_modified</th>\n",
        "      <th>content_type</th>\n",
        "      <th>content_length</th>\n",
        "      <th>blob_type</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> any/DonnotLaugel/allNetflixData.csv</td>\n",
        "      <td> Mon, 02 Feb 2015 00:19:18 GMT</td>\n",
        "      <td> application/octet-stream</td>\n",
        "      <td> 2610540689</td>\n",
        "      <td> BlockBlob</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>  any/DonnotLaugel/xd/mv_0000001.txt</td>\n",
        "      <td> Sun, 01 Feb 2015 18:23:18 GMT</td>\n",
        "      <td> application/octet-stream</td>\n",
        "      <td>      11233</td>\n",
        "      <td> BlockBlob</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>2 rows \u00d7 5 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "                                  name                  last_modified  \\\n",
        "0  any/DonnotLaugel/allNetflixData.csv  Mon, 02 Feb 2015 00:19:18 GMT   \n",
        "1   any/DonnotLaugel/xd/mv_0000001.txt  Sun, 01 Feb 2015 18:23:18 GMT   \n",
        "\n",
        "               content_type  content_length  blob_type  \n",
        "0  application/octet-stream      2610540689  BlockBlob  \n",
        "1  application/octet-stream           11233  BlockBlob  \n",
        "\n",
        "[2 rows x 5 columns]"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "On s\u00e9pare la base entre train et test :"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%PIG createTrainTest.pig\n",
      "\n",
      "allData = LOAD '/any/DonnotLaugel/allNetflixData.csv' USING PigStorage(',') AS (movie:int user:int rating:int date:datetime );\n",
      "\n",
      "values_train = FILTER allData BY date <= datetime(\"2009-06-30\") ;\n",
      "values_test = FILTER allData BY date > datetime(\"2009-06-30\") ;\n",
      "\n",
      "STORE values_train INTO '/any/DonnotLaugel/NetflixData_Train-2009-06-30.csv' USING PigStorage(',') ;\n",
      "STORE values_test INTO '/any/DonnotLaugel/NetflixData_Test-2009-06-30.csv' USING PigStorage(',') ;"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%PIG createTrainTest.pig\n",
      "\n",
      "values = LOAD '/any/DonnotLaugel/allNetflixData.csv' USING PigStorage(',') AS (movie:int user:int rating:int date:datetime);\n",
      "\n",
      "values_Train = FILTER values BY date <= datetime($dateMin) ;\n",
      "values_Test = FILTER values BY date > datetime($dateMin) ;\n",
      "\n",
      "STORE values_Train INTO '/any/DonnotLaugel/NetflixData_Train-$dateMin.csv' USING PigStorage(',') ;\n",
      "STORE values_Test INTO '/any/DonnotLaugel/NetflixData_Test-$dateMin.csv' USING PigStorage(',') ;"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "(<pyensae.remote.azure_connection.AzureClient at 0x99f4b10>,\n",
        " <azure.storage.blobservice.BlobService at 0x99f4b50>)"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "On envoie le job :"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "paramsPig = {\"dateMin\":\"2009-06-30\"}\n",
      "#client.pig_submit(bs, client.account_name, \"createTrainTest.pig\",params = paramsPig )\n",
      "client.pig_submit(bs, client.account_name, \"createTrainTest.pig\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "AzureException",
       "evalue": "STATUS: 500, JSON: {'error': None}\nunable to submit job: hdblobstorage",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mAzureException\u001b[0m                            Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-19-4fe0b99dbefb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mparamsPig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"dateMin\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m\"2009-06-30\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#client.pig_submit(bs, client.account_name, \"createTrainTest.pig\",params = paramsPig )\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mclient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpig_submit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccount_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"createTrainTest.pig\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;32m\\\\ensae.fr\\dfsgenes\\SourceLogicielsSeven\\Python\\WinPython\\python-3.3.5.amd64\\lib\\site-packages\\pyensae-py3.3_1.1.1-py3.3.egg\\pyensae\\remote\\azure_connection.py\u001b[0m in \u001b[0;36mpig_submit\u001b[1;34m(self, container_name, blob_pig, status_dir)\u001b[0m\n\u001b[0;32m    508\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 510\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAzureException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"unable to submit job: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mblob_pig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    511\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mAzureException\u001b[0m: STATUS: 500, JSON: {'error': None}\nunable to submit job: hdblobstorage"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "On v\u00e9rifie que le job s'ex\u00e9cute normalement :"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#don't forget to change the job_id ...\n",
      "st = %hd_job_status job_1416874839254_0202\n",
      "st[\"id\"],st[\"percentComplete\"],st[\"status\"][\"jobComplete\"]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "On ferme la connexion"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%blob_close"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 21,
       "text": [
        "True"
       ]
      }
     ],
     "prompt_number": 21
    }
   ],
   "metadata": {}
  }
 ]
}