{
 "metadata": {
  "name": "",
  "signature": "sha256:8ee59da9881b6ecf37bb09ced1d057051801353248b749e5bb3b3d1cb7e025be"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "On divise le data set entre train et test"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "On charge les libraries voulues :"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pyensae\n",
      "import pyquickhelper\n",
      "import pandas, sqlite3, os\n",
      "path = \"data/\"\n",
      "pathTrain = path+\"training_set/\"\n",
      "pathWD = \"\\\\\\\\paradis\\\\eleves\\\\BDonnot\\\\Bureau\\\\DonneesMassives\\\\\"\n",
      "#os.chdir(pathWD)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "On se connecte au serveur"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "params={\"blob_storage\":\"hdblobstorage\", \"password1\":\"\", \"hadoop_server\":\"clusterensaeazure1\", \"password2\":\"\", \"username\":\"DonnotLaugel\"}\n",
      "with open(\"password\",\"r\") as fPassWord :\n",
      "    for line in fPassWord :\n",
      "        li = line.split(\":\")\n",
      "        if li[0] == params[\"blob_storage\"] :\n",
      "            params[\"password1\"] = li[1].replace('\\n','').replace('\\r','')\n",
      "        elif li[0] == params[\"hadoop_server\"] :\n",
      "            params[\"password2\"] = li[1].replace('\\n','').replace('\\r','')\n",
      "blobstorage = params[\"blob_storage\"]\n",
      "blobpassword = params[\"password1\"]\n",
      "hadoop_server = params[\"hadoop_server\"]\n",
      "hadoop_password = params[\"password2\"]\n",
      "username = params[\"username\"]\n",
      "client, bs =  %hd_open\n",
      "client, bs,client.account_name,username\n",
      "#pyquickhelper.open_html_form(params=params,title=\"server + hadoop + credentials\", key_save=\"blobhp\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "(<pyensae.remote.azure_connection.AzureClient at 0x7fb9ce7928d0>,\n",
        " <azure.storage.blobservice.BlobService at 0x7fb9ce792748>,\n",
        " 'hdblobstorage',\n",
        " 'DonnotLaugel')"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "On v\u00e9rifie que les pr\u00e9c\u00e9dents fichiers sont bien l\u00e0"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "l = %blob_containers\n",
      "l\n",
      "%blob_ls /$PSEUDO/DonnotLaugel"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>name</th>\n",
        "      <th>last_modified</th>\n",
        "      <th>content_type</th>\n",
        "      <th>content_length</th>\n",
        "      <th>blob_type</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> DonnotLaugel/DonnotLaugel/allNetflixData.csv</td>\n",
        "      <td> Mon, 02 Feb 2015 16:59:38 GMT</td>\n",
        "      <td> application/octet-stream</td>\n",
        "      <td> 2610540665</td>\n",
        "      <td> BlockBlob</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "                                           name  \\\n",
        "0  DonnotLaugel/DonnotLaugel/allNetflixData.csv   \n",
        "\n",
        "                   last_modified              content_type  content_length  \\\n",
        "0  Mon, 02 Feb 2015 16:59:38 GMT  application/octet-stream      2610540665   \n",
        "\n",
        "   blob_type  \n",
        "0  BlockBlob  "
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Convertit les dates au bon format"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%PIG convertDate.pig\n",
      "allData = LOAD '$CONTAINER/$PSEUDO/DonnotLaugel/allNetflixData.csv' USING PigStorage(',') AS (movie:int,user:int,rating:int,date:chararray );\n",
      "values = FOREACH allData GENERATE toDate(date,'YYYY-MM-dd') AS date2 ;\n",
      "STORE values INTO '$CONTAINER/$PSEUDO/DonnotLaugel/allNetflixDataClean.csv' USING PigStorage(',') ;"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "client.pig_submit(bs, client.account_name, 'convertDate.pig')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "AzureException",
       "evalue": "STATUS: 403, JSON: Expecting value: line 1 column 1 (char 0)\n<Response [403]>\nunable to submit job: convertDate.pig",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mAzureException\u001b[0m                            Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-13-c2073b9a5a57>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpig_submit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccount_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'convertDate.pig'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;32m/usr/local/lib/python3.4/dist-packages/pyensae/remote/azure_connection.py\u001b[0m in \u001b[0;36mpig_submit\u001b[1;34m(self, blob_service, container_name, pig_file, dependencies, status_dir, stop_on_failure, params)\u001b[0m\n\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    638\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 639\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAzureException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"unable to submit job: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mpig_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    640\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mAzureException\u001b[0m: STATUS: 403, JSON: Expecting value: line 1 column 1 (char 0)\n<Response [403]>\nunable to submit job: convertDate.pig"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#don't forget to change the job_id ...\n",
      "st = %hd_job_status job_1416874839254_0202\n",
      "st[\"id\"],st[\"percentComplete\"],st[\"status\"][\"jobComplete\"]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "On s\u00e9pare la base entre train et test :"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%PIG createTrainTest.pig\n",
      "allData = LOAD '$CONTAINER/$PSEUDO/DonnotLaugel/allNetflixData.csv' USING PigStorage(',') AS (movie:int,user:int,rating:int,date:chararray );\n",
      "values_train = FILTER allData BY date <= datetime(\"2009-06-30\") ;\n",
      "values_test = FILTER allData BY date > datetime(\"2009-06-30\") ;\n",
      "STORE values_train INTO '$CONTAINER/$PSEUDO/DonnotLaugel/NetflixData_Train-2009-06-30.csv' USING PigStorage(',') ;\n",
      "STORE values_test INTO '$CONTAINER/$PSEUDO/DonnotLaugel/NetflixData_Test-2009-06-30.csv' USING PigStorage(',') ;"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%PIG createTrainTest.pig\n",
      "values = LOAD '$CONTAINER/$PSEUDO/DonnotLaugel/allNetflixData.csv' USING PigStorage(',') AS (movie:int user:int rating:int date:datetime);\n",
      "values_Train = FILTER values BY date <= datetime($dateMin) ;\n",
      "values_Test = FILTER values BY date > datetime($dateMin) ;\n",
      "STORE values_Train INTO '$CONTAINER/$PSEUDO/DonnotLaugel/NetflixData_Train-$dateMin.csv' USING PigStorage(',') ;\n",
      "STORE values_Test INTO '$CONTAINER/$PSEUDO/DonnotLaugel/NetflixData_Test-$dateMin.csv' USING PigStorage(',') ;"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "On envoie le job :"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "paramsPig = {\"dateMin\":\"2009-06-30\"}\n",
      "client.pig_submit(bs, client.account_name, \"createTrainTest.pig\",params = paramsPig )\n",
      "#client.pig_submit(bs, client.account_name, \"createTrainTest.pig\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "AzureException",
       "evalue": "STATUS: 403, JSON: Expecting value: line 1 column 1 (char 0)\n<Response [403]>\nunable to submit job: createTrainTest.pig",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mAzureException\u001b[0m                            Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-8-b0f528740ca2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mparamsPig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"dateMin\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m\"2009-06-30\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mclient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpig_submit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccount_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"createTrainTest.pig\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparamsPig\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m#client.pig_submit(bs, client.account_name, \"createTrainTest.pig\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/local/lib/python3.4/dist-packages/pyensae/remote/azure_connection.py\u001b[0m in \u001b[0;36mpig_submit\u001b[1;34m(self, blob_service, container_name, pig_file, dependencies, status_dir, stop_on_failure, params)\u001b[0m\n\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    638\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 639\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAzureException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"unable to submit job: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mpig_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    640\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mAzureException\u001b[0m: STATUS: 403, JSON: Expecting value: line 1 column 1 (char 0)\n<Response [403]>\nunable to submit job: createTrainTest.pig"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "On v\u00e9rifie que le job s'ex\u00e9cute normalement :"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#don't forget to change the job_id ...\n",
      "st = %hd_job_status job_1416874839254_0202\n",
      "st[\"id\"],st[\"percentComplete\"],st[\"status\"][\"jobComplete\"]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "On ferme la connexion"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%blob_close"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 21,
       "text": [
        "True"
       ]
      }
     ],
     "prompt_number": 21
    }
   ],
   "metadata": {}
  }
 ]
}